{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# считываем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "                                        \n",
    "test = pd.read_csv('test.csv')\n",
    "songs = pd.read_csv('songs.csv')\n",
    "members = pd.read_csv('members.csv',\n",
    "                     parse_dates=['registration_init_time','expiration_date'])\n",
    "\n",
    "songs_extra = pd.read_csv('song_extra_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# составим датасет всех песен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sngs = pd.merge(songs_extra.loc[:, ['song_id', 'name']], songs.loc[:, ['song_id', 'artist_name', 'genre_ids']], on=['song_id', 'song_id'], how='right')\n",
    "\n",
    "sngs.name = sngs.name.astype(str)\n",
    "sngs.artist_name = sngs.artist_name.astype(str)\n",
    "\n",
    "sngs['full_name'] = sngs.loc[:, ['name', 'artist_name']].apply(lambda x: x['name'] + ' | ' +  x['artist_name'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# почему то у одной песни могут быть разные хеши, учтем "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>p+WxS35GIo9lHYpW17Bz/PRW+UcGH9R+bq+wU2caYnY=</td>\n",
       "      <td>Lose Yourself</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>1259</td>\n",
       "      <td>Lose Yourself | Eminem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111600</th>\n",
       "      <td>ARjGxZVGrJXEEqIXk/5+67G/nqC1FdH3AuwSQQ1m5G8=</td>\n",
       "      <td>Lose Yourself</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>1259</td>\n",
       "      <td>Lose Yourself | Eminem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447109</th>\n",
       "      <td>MSCKTsjyD7Urq/vbunDlHmc/xcFrpZ9noEbPrewKxms=</td>\n",
       "      <td>Lose Yourself</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>1259</td>\n",
       "      <td>Lose Yourself | Eminem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231614</th>\n",
       "      <td>H5vEv5ogrztWon/cj1ZacsNIJzFnQmAytb+ARVjLrA8=</td>\n",
       "      <td>Lose Yourself</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>1259</td>\n",
       "      <td>Lose Yourself | Eminem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              song_id           name  \\\n",
       "1381     p+WxS35GIo9lHYpW17Bz/PRW+UcGH9R+bq+wU2caYnY=  Lose Yourself   \n",
       "111600   ARjGxZVGrJXEEqIXk/5+67G/nqC1FdH3AuwSQQ1m5G8=  Lose Yourself   \n",
       "1447109  MSCKTsjyD7Urq/vbunDlHmc/xcFrpZ9noEbPrewKxms=  Lose Yourself   \n",
       "2231614  H5vEv5ogrztWon/cj1ZacsNIJzFnQmAytb+ARVjLrA8=  Lose Yourself   \n",
       "\n",
       "        artist_name genre_ids               full_name  \n",
       "1381         Eminem      1259  Lose Yourself | Eminem  \n",
       "111600       Eminem      1259  Lose Yourself | Eminem  \n",
       "1447109      Eminem      1259  Lose Yourself | Eminem  \n",
       "2231614      Eminem      1259  Lose Yourself | Eminem  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sngs.loc[sngs.full_name == 'Lose Yourself | Eminem']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# утвердим единый хеш для пары песня-исполнитель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_dict = {}\n",
    "for row in sngs.to_numpy():\n",
    "    song_id, name, artist_name, genre_ids, full_name = row\n",
    "    songs_dict[full_name] = song_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# соберем тренировочный датасет для эмбедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_songs = train.loc[train.target == 1].loc[:, ['msno', 'song_id']].dropna()\n",
    "usr_songs = usr_songs.merge(sngs, on=['song_id', 'song_id'])\n",
    "usr_songs.song_id = usr_songs.loc[:, ['song_id', 'full_name']].apply(lambda x: songs_dict[x['full_name']], axis=1)\n",
    "\n",
    "song_dict = dict([(j, i) for i, j in enumerate(usr_songs.song_id.unique())])\n",
    "user_dict = dict([(j, i) for i, j in enumerate(usr_songs.msno.unique())])\n",
    "\n",
    "usr_songs = usr_songs.loc[:, ['msno', 'song_id', 'name', 'artist_name', 'genre_ids', 'full_name']]\n",
    "usr_songs = usr_songs.dropna()\n",
    "\n",
    "usr_songs.msno = usr_songs.msno.apply(lambda x: user_dict[x])\n",
    "usr_songs.song_id = usr_songs.song_id.apply(lambda x: song_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# исправили множественные хеши"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10816    210\n",
       "Name: song_id, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usr_songs.loc[(usr_songs.name == 'Lose Yourself') & (usr_songs.artist_name == 'Eminem')].song_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# сделаем плейлисты юзеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    }
   ],
   "source": [
    "play_lists = []\n",
    "for u_id in tqdm(usr_songs.msno.unique(), position=0,leave=False):\n",
    "    songs = usr_songs.loc[usr_songs.msno == u_id].song_id.values.tolist()\n",
    "    play_lists.append(songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import logging\n",
    "from time import time\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for i in range(len(play_lists)):\n",
    "    lengths.append(len(play_lists[i]))\n",
    "    play_lists[i] = list(map(str, play_lists[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135.04594474811643"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# средняя длина предложения\n",
    "np.mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO)\n",
    "\n",
    "class Callback(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 1\n",
    "        self.training_loss = []\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 1:\n",
    "            current_loss = loss\n",
    "        else:\n",
    "            current_loss = loss - self.loss_previous_step\n",
    "        print(f\"Loss after epoch {self.epoch}: {current_loss}\")\n",
    "        self.training_loss.append(current_loss)\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=0, size=256, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "# обучим word2vec\n",
    "model = Word2Vec(\n",
    "    size = 256,\n",
    "    window = 10,\n",
    "    min_count = 1,\n",
    "    sg = 0,\n",
    "    negative = 20,\n",
    "    workers = multiprocessing.cpu_count())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-25 22:55:23,022 : INFO : collecting all words and their counts\n",
      "2020-10-25 22:55:23,025 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-10-25 22:55:23,513 : INFO : PROGRESS: at sentence #10000, processed 2531600 words, keeping 137261 word types\n",
      "2020-10-25 22:55:23,801 : INFO : PROGRESS: at sentence #20000, processed 3486968 words, keeping 176209 word types\n",
      "2020-10-25 22:55:23,862 : INFO : collected 191425 word types from a corpus of 3656504 raw words and 27076 sentences\n",
      "2020-10-25 22:55:23,863 : INFO : Loading a fresh vocabulary\n",
      "2020-10-25 22:55:24,337 : INFO : effective_min_count=1 retains 191425 unique words (100% of original 191425, drops 0)\n",
      "2020-10-25 22:55:24,338 : INFO : effective_min_count=1 leaves 3656504 word corpus (100% of original 3656504, drops 0)\n",
      "2020-10-25 22:55:24,868 : INFO : deleting the raw counts dictionary of 191425 items\n",
      "2020-10-25 22:55:24,872 : INFO : sample=0.001 downsamples 4 most-common words\n",
      "2020-10-25 22:55:24,873 : INFO : downsampling leaves estimated 3654463 word corpus (99.9% of prior 3656504)\n",
      "2020-10-25 22:55:25,332 : INFO : estimated required memory for 191425 words and 256 dimensions: 487750900 bytes\n",
      "2020-10-25 22:55:25,333 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 35.29 seconds\n"
     ]
    }
   ],
   "source": [
    "logging.disable(logging.NOTSET) # enable logging\n",
    "t = time()\n",
    "\n",
    "model.build_vocab(play_lists)\n",
    "\n",
    "print(f\"Time to build vocab: {round((time() - t), 2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 1: 2894918.75\n",
      "Loss after epoch 2: 1648220.25\n",
      "Loss after epoch 3: 1428155.0\n",
      "Loss after epoch 4: 1328166.0\n",
      "Loss after epoch 5: 1290266.0\n",
      "Loss after epoch 6: 1202057.0\n",
      "Loss after epoch 7: 1174462.0\n",
      "Loss after epoch 8: 1158547.0\n",
      "Loss after epoch 9: 1160841.0\n",
      "Loss after epoch 10: 1110437.0\n",
      "Loss after epoch 11: 1091062.0\n",
      "Loss after epoch 12: 1069668.0\n",
      "Loss after epoch 13: 971928.0\n",
      "Loss after epoch 14: 949088.0\n",
      "Loss after epoch 15: 933218.0\n",
      "Loss after epoch 16: 923592.0\n",
      "Loss after epoch 17: 922830.0\n",
      "Loss after epoch 18: 903334.0\n",
      "Loss after epoch 19: 896566.0\n",
      "Loss after epoch 20: 892130.0\n",
      "Loss after epoch 21: 873648.0\n",
      "Loss after epoch 22: 861804.0\n",
      "Loss after epoch 23: 858724.0\n",
      "Loss after epoch 24: 853104.0\n",
      "Loss after epoch 25: 858686.0\n",
      "Loss after epoch 26: 844330.0\n",
      "Loss after epoch 27: 853000.0\n",
      "Loss after epoch 28: 844394.0\n",
      "Loss after epoch 29: 829708.0\n",
      "Loss after epoch 30: 842164.0\n",
      "Loss after epoch 31: 818884.0\n",
      "Loss after epoch 32: 686892.0\n",
      "Loss after epoch 33: 616724.0\n",
      "Loss after epoch 34: 615444.0\n",
      "Loss after epoch 35: 617200.0\n",
      "Loss after epoch 36: 602588.0\n",
      "Loss after epoch 37: 608464.0\n",
      "Loss after epoch 38: 591928.0\n",
      "Loss after epoch 39: 591020.0\n",
      "Loss after epoch 40: 595604.0\n",
      "Loss after epoch 41: 595960.0\n",
      "Loss after epoch 42: 582912.0\n",
      "Loss after epoch 43: 586760.0\n",
      "Loss after epoch 44: 593144.0\n",
      "Loss after epoch 45: 584592.0\n",
      "Loss after epoch 46: 590948.0\n",
      "Loss after epoch 47: 588260.0\n",
      "Loss after epoch 48: 579900.0\n",
      "Loss after epoch 49: 572804.0\n",
      "Loss after epoch 50: 579656.0\n",
      "Loss after epoch 51: 566632.0\n",
      "Loss after epoch 52: 562192.0\n",
      "Loss after epoch 53: 568784.0\n",
      "Loss after epoch 54: 562064.0\n",
      "Loss after epoch 55: 553364.0\n",
      "Loss after epoch 56: 554980.0\n",
      "Loss after epoch 57: 549732.0\n",
      "Loss after epoch 58: 551816.0\n",
      "Loss after epoch 59: 558256.0\n",
      "Loss after epoch 60: 550968.0\n",
      "Loss after epoch 61: 545904.0\n",
      "Loss after epoch 62: 539608.0\n",
      "Loss after epoch 63: 535272.0\n",
      "Loss after epoch 64: 532896.0\n",
      "Loss after epoch 65: 536472.0\n",
      "Loss after epoch 66: 528936.0\n",
      "Loss after epoch 67: 518144.0\n",
      "Loss after epoch 68: 516408.0\n",
      "Loss after epoch 69: 504048.0\n",
      "Loss after epoch 70: 498568.0\n",
      "Loss after epoch 71: 498796.0\n",
      "Loss after epoch 72: 489716.0\n",
      "Loss after epoch 73: 495988.0\n",
      "Loss after epoch 74: 490220.0\n",
      "Loss after epoch 75: 480880.0\n",
      "Loss after epoch 76: 469396.0\n",
      "Loss after epoch 77: 473540.0\n",
      "Loss after epoch 78: 464496.0\n",
      "Loss after epoch 79: 451384.0\n",
      "Loss after epoch 80: 446132.0\n",
      "Loss after epoch 81: 442336.0\n",
      "Loss after epoch 82: 438712.0\n",
      "Loss after epoch 83: 436480.0\n",
      "Loss after epoch 84: 429164.0\n",
      "Loss after epoch 85: 415852.0\n",
      "Loss after epoch 86: 411388.0\n",
      "Loss after epoch 87: 394336.0\n",
      "Loss after epoch 88: 396352.0\n",
      "Loss after epoch 89: 383696.0\n",
      "Loss after epoch 90: 374696.0\n",
      "Loss after epoch 91: 360852.0\n",
      "Loss after epoch 92: 361436.0\n",
      "Loss after epoch 93: 342976.0\n",
      "Loss after epoch 94: 334328.0\n",
      "Loss after epoch 95: 319820.0\n",
      "Loss after epoch 96: 312680.0\n",
      "Loss after epoch 97: 303976.0\n",
      "Loss after epoch 98: 291360.0\n",
      "Loss after epoch 99: 155388.0\n",
      "Loss after epoch 100: 87136.0\n",
      "Time to train the model: 1081.27 seconds\n"
     ]
    }
   ],
   "source": [
    "logging.disable(logging.INFO) # disable logging\n",
    "callback = Callback() # instead, print out loss for each epoch\n",
    "t = time()\n",
    "\n",
    "model.train(play_lists,\n",
    "            total_examples = model.corpus_count,\n",
    "            epochs = 100,\n",
    "            compute_loss = True,\n",
    "            callbacks = [callback]) \n",
    "\n",
    "print(f\"Time to train the model: {round((time() - t), 2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sngs.song_id = sngs.apply(lambda x: songs_dict[x['full_name']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sngs.song_id = sngs.song_id.apply(lambda x: song_dict[x] if x in song_dict else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sngs = sngs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>full_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>10816</td>\n",
       "      <td>Lose Yourself</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>1259</td>\n",
       "      <td>Lose Yourself | Eminem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     song_id           name artist_name genre_ids               full_name\n",
       "1381   10816  Lose Yourself      Eminem      1259  Lose Yourself | Eminem"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sngs.loc[(sngs.artist_name == 'Eminem') & (sngs.name =='Lose Yourself')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('11274', 0.5260806083679199)\n",
      "\t1259 Eminem Not Afraid\n",
      "\n",
      "('10023', 0.48443353176116943)\n",
      "\t1259 Eminem Space Bound\n",
      "\n",
      "('10301', 0.4646959900856018)\n",
      "\t1259 Flo Rida I Cry\n",
      "\n",
      "('10881', 0.4475036859512329)\n",
      "\t465 Air Supply Goodbye\n",
      "\n",
      "('10699', 0.41769152879714966)\n",
      "\t1259 Flo Rida Who's With Me\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ms in model.wv.most_similar('10816')[:5]:\n",
    "    print(ms, end='\\n\\t')\n",
    "    found = sngs.loc[sngs.song_id.astype(str) == ms[0]]\n",
    "    print(found.genre_ids.item(), found.artist_name.item(), found.name.item())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
